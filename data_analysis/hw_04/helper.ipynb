{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "p5dL4YeVorzV"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "torch.backends.mps.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "feGo1EKE4sRg"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26.4M/26.4M [00:02<00:00, 9.23MB/s]\n",
      "100%|██████████| 29.5k/29.5k [00:00<00:00, 191kB/s]\n",
      "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.46MB/s]\n",
      "100%|██████████| 5.15k/5.15k [00:00<00:00, 7.85MB/s]\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = 'data/'\n",
    "\n",
    "# Use the following code to load and normalize the dataset for training and testing\n",
    "# It will downlad the dataset into data subfolder (change to your data folder name)\n",
    "\n",
    "magic_number_1 = 0.1307\n",
    "magic_number_2 = 0.3081\n",
    "\n",
    "transform_for_data = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(\n",
    "            (magic_number_1,),\n",
    "            (magic_number_2,)\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_dataset = torchvision.datasets.FashionMNIST(\n",
    "    DATA_DIR,\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform_for_data,\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.FashionMNIST(\n",
    "    DATA_DIR,\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform_for_data,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the following code to create a validation set of 10%\n",
    "split_size = 0.1\n",
    "\n",
    "train_indices, val_indices, _, _ = train_test_split(\n",
    "    range(len(train_dataset)),\n",
    "    train_dataset.targets,\n",
    "    stratify=train_dataset.targets,\n",
    "    test_size=split_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training and validation subsets based on indices\n",
    "train_split = Subset(train_dataset, train_indices)\n",
    "val_split = Subset(train_dataset, val_indices)\n",
    "\n",
    "\n",
    "# set batches sizes\n",
    "train_batch_size = 512 #Define train batch size\n",
    "test_batch_size  = 256 #Define test batch size (can be larger than train batch size)\n",
    "\n",
    "\n",
    "# Define dataloader objects that help to iterate over batches and samples for\n",
    "# training, validation and testing\n",
    "train_batches = DataLoader(train_split, batch_size=train_batch_size, shuffle=True)\n",
    "val_batches = DataLoader(val_split, batch_size=train_batch_size, shuffle=True)\n",
    "test_batches = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=True)\n",
    "                                           \n",
    "num_train_batches=len(train_batches)\n",
    "num_val_batches=len(val_batches)\n",
    "num_test_batches=len(test_batches)\n",
    "\n",
    "\n",
    "print(num_train_batches)\n",
    "print(num_val_batches)\n",
    "print(num_test_batches)\n",
    "\n",
    "\n",
    "#Sample code to visulaize the first sample in first 16 batches \n",
    "\n",
    "# batch_num = 0\n",
    "# for train_features, train_labels in train_batches:\n",
    "    \n",
    "#     if batch_num == 16:\n",
    "#         break    # break here\n",
    "    \n",
    "#     batch_num = batch_num +1\n",
    "#     print(f\"Feature batch shape: {train_features.size()}\")\n",
    "#     print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "    \n",
    "#     img = train_features[0].squeeze()\n",
    "#     label = train_labels[0]\n",
    "#     plt.imshow(img, cmap=\"gray\")\n",
    "#     plt.show()\n",
    "#     print(f\"Label: {label}\")\n",
    "\n",
    "\n",
    "\n",
    "# Sample code to plot N^2 images from the dataset\n",
    "# def plot_images(XX, N, title):\n",
    "#     fig, ax = plt.subplots(N, N, figsize=(8, 8))\n",
    "    \n",
    "#     for i in range(N):\n",
    "#       for j in range(N):\n",
    "#         ax[i,j].imshow(XX[(N)*i+j], cmap=\"Greys\")\n",
    "#         ax[i,j].axis(\"off\")\n",
    "#     fig.suptitle(title, fontsize=24)\n",
    "\n",
    "# plot_images(train_dataset.data[:64], 8, \"First 64 Training Images\" )\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "HrvoPg1f7Gxu"
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (3397305973.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [2]\u001b[0;36m\u001b[0m\n\u001b[0;31m    #Define how your model propagates the input through the network\u001b[0m\n\u001b[0m                                                                   ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "#Define your (As Cool As It Gets) Fully Connected Neural Network \n",
    "class ACAIGFCN(nn.Module):\n",
    "    #Initialize model layers, add additional arguments to adjust\n",
    "    def __init__(self, input_dim, output_dim): \n",
    "        super(ACAIGFCN, self).__init__()\n",
    "        #Define the network layer(s) and activation function(s)\n",
    " \n",
    "    def forward(self, input):\n",
    "        #Define how your model propagates the input through the network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "0F_DyktW8Bgw"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3171035009.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [3]\u001b[0;36m\u001b[0m\n\u001b[0;31m    learning_rate =\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Initialize neural network model with input, output and hidden layer dimensions\n",
    "model = ACAIGFCN(input_dim = 784, output_dim = 10) #... add more parameters\n",
    "                \n",
    "# Define the learning rate and epochs number\n",
    "learning_rate =\n",
    "epochs =\n",
    "\n",
    "\n",
    "train_loss_list = np.zeros((epochs,))\n",
    "validation_accuracy_list = np.zeros((epochs,))\n",
    "\n",
    "# Define loss function  and optimizer\n",
    "loss_func = # Use Cross Entropy loss from torch.nn \n",
    "optimizer = # Use optimizers from torch.optim\n",
    "\n",
    "\n",
    "# Iterate over epochs, batches with progress bar and train+ validate the ACAIGFCN\n",
    "# Track the loss and validation accuracy\n",
    "for epoch in tqdm.trange(epochs):\n",
    "\n",
    "    # ACAIGFCN Training \n",
    "    for train_features, train_labels in train_batches:\n",
    "        # Set model into training mode\n",
    "        model.train()\n",
    "        \n",
    "        # Reshape images into a vector\n",
    "        train_features = train_features.reshape(-1, 28*28)\n",
    "\n",
    "        # Reset gradients, Calculate training loss on model \n",
    "        # Perfrom optimization, back propagation\n",
    " \n",
    "    # Record loss for the epoch\n",
    "    \n",
    "    # ACAIGFCN Validation\n",
    "    for val_features, val_labels in val_batches:\n",
    "        \n",
    "        # Telling PyTorch we aren't passing inputs to network for training purpose\n",
    "        with torch.no_grad(): \n",
    "            model.eval()\n",
    "            \n",
    "             # Reshape validation images into a vector\n",
    "            val_features = val_features.reshape(-1, 28*28)\n",
    "          \n",
    "            # Compute validation outputs (targets) \n",
    "            # and compute accuracy \n",
    "            \n",
    "    # Record accuracy for the epoch; print training loss, validation accuracy\n",
    "    print(\"Epoch: \"+ str(epoch) +\"; Validation Accuracy:\" + str(val_acc/num_val_batches*100) + '%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training loss and validation accuracy throughout the training epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate accuracy on test set\n",
    "\n",
    "# Telling PyTorch we aren't passing inputs to network for training purpose\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for test_features, test_labels in test_batches:\n",
    "\n",
    "        model.eval()\n",
    "        # Reshape test images into a vector\n",
    "        test_features = test_features.reshape(-1, 28*28)\n",
    "\n",
    "         # Compute validation outputs (targets) \n",
    "         # and compute accuracy \n",
    "    \n",
    "    # Compute total (mean) accuracy\n",
    "    # Report total (mean) accuracy, can also compute std based on batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "EM6GQLv6j5uH"
   ],
   "name": "Lab 2- PyTorch Basics.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "uw-dev-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
